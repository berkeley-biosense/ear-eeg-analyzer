{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# data marshalling\n",
    "\n",
    "first, we'll need a method to find recordings by subject ID and task name\n",
    "\n",
    "we'll also produce a list `subject_ids` of all subjects, and `task_names` of all tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('data')\n",
    "\n",
    "def subject_id (filename):\n",
    "    return filename.split('.')[0]\n",
    "\n",
    "def task_name (filename):\n",
    "    return filename.split('.')[1]\n",
    "\n",
    "subject_ids = list(set(map(subject_id, files)))\n",
    "task_names = list(set(map(task_name, files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['002.breathe_o.1478914139385.csv',\n '002.breathe_o.1478915038323.csv',\n '002.breathe_o.1478915049512.csv',\n '002.breathe_o.1478915025849.csv',\n '002.breathe_o.1478914092279.csv',\n '002.breathe_o.1478914127598.csv',\n '002.breathe_o.1478915002519.csv',\n '002.breathe_o.1478914104820.csv',\n '002.breathe_o.1478915013777.csv',\n '002.breathe_o.1478914116257.csv']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def find_with_id (id):\n",
    "    return lambda filename: subject_id(filename) == id\n",
    "\n",
    "def find_with_task (task):\n",
    "    return lambda filename: task_name(filename) == task\n",
    "\n",
    "# both args are optional\n",
    "def find_recordings (id=None, task=None):\n",
    "    lst = files\n",
    "    if id:\n",
    "        lst = list(filter(find_with_id(id), lst))\n",
    "    if task:\n",
    "        lst = list(filter(find_with_task(task), lst))\n",
    "    return lst\n",
    "\n",
    "find_recordings(task='breathe_o')\n",
    "find_recordings('002', 'breathe_o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "now, we will want positive and negative examples for training. \n",
    "\n",
    "for a given subject and task, we need examples of the correct person performing the task (positive examples), and examples of the incorrect person performing the task (negative examples).\n",
    "\n",
    "but, first, we will need to create some feature vectors. let's load up a file and look at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ffff/.local/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['rate']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "def load_recording (filename):\n",
    "    df = pd.read_csv(join('data', filename), header=None)\n",
    "    return df.drop(df.columns[[0,2,3,4,5,7]], 1)  # drop all columns but 1 and 6\n",
    "\n",
    "#load_reading(files[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 25)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "from scipy.interpolate import interp1d\n",
    "from functools import partial\n",
    "\n",
    "def grouper (n, iterable):\n",
    "    \"grouper(3, 'ABCDEFG', 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return list(itertools.zip_longest(*args))[:-1]\n",
    "\n",
    "def spectrum (vector):\n",
    "    '''get the power spectrum of a vector of raw EEG data'''\n",
    "    A = np.fft.fft(vector)\n",
    "    ps = np.abs(A)*2.0\n",
    "    ps = ps[:len(ps)//2]\n",
    "    return ps\n",
    "\n",
    "def binned (pspectra, n):\n",
    "    '''compress an array of power spectra into vectors of length n'''\n",
    "    l = len(pspectra)\n",
    "    array = np.zeros([l,n])\n",
    "    for i,ps in enumerate(pspectra):\n",
    "        x = np.arange(1,len(ps)+1)\n",
    "        f = interp1d(x,ps)#/np.sum(ps))\n",
    "        array[i] = f(np.arange(1, n+1))\n",
    "    index = np.argwhere(array[:,0]==-1)\n",
    "    array = np.delete(array,index,0)\n",
    "    return array\n",
    "\n",
    "def feature_vector (bins, readings): # A function we apply to each group of power spectra\n",
    "  '''\n",
    "  Create 100, log10-spaced bins for each power spectrum.\n",
    "  For more on how this particular implementation works, see:\n",
    "      http://people.ischool.berkeley.edu/~chuang/pubs/MMJC15.pdf\n",
    "  '''\n",
    "  bins = binned(list(map(spectrum, readings)), bins)\n",
    "  return np.log10(np.mean(bins, 0))\n",
    "\n",
    "def features (raws, bins=50, time_resolution=250, spectra_compression=2 ):\n",
    "    featureVectorF = partial(feature_vector, bins)\n",
    "    spectra = map(spectrum, grouper(time_resolution, raws))\n",
    "    groupedSpectra = grouper(spectra_compression, spectra)\n",
    "    vs = list(map(featureVectorF, groupedSpectra))\n",
    "    return np.array(vs)\n",
    "\n",
    "breathe = load_recording(find_recordings(task='breathe')[0])\n",
    "features(breathe[1], bins=25, spectra_compression=1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "def cross_val_svm (X,y,n):\n",
    "    clf = svm.SVC()\n",
    "    scores = cross_val_score(clf, X, y, cv=n)\n",
    "    return scores    \n",
    "\n",
    "def vectors_labels (list1, list2):\n",
    "    def label (l):\n",
    "        return lambda x: l\n",
    "    X = np.concatenate([list1, list2])\n",
    "    y = list(map(label(0), list1)) + list(map(label(1), list2))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "max_sport = load_recording(\n",
    "          find_recordings(id=\"001\", task='sport')[0])\n",
    "john_sport = load_recording(\n",
    "           find_recordings(id=\"002\", task='sport')[0])\n",
    "\n",
    "X, y = vectors_labels(\n",
    "    features(max_sport[1]),\n",
    "    features(john_sport[1]))\n",
    "\n",
    "cross_val_svm(X,y,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "t_res = 400\n",
    "bns   = t_res//4\n",
    "cmprs = 1\n",
    "\n",
    "def featureify (acc, df, bins=bns, time_res=t_res, spectra_compress=cmprs):\n",
    "    f = lambda df, n: features(df[n], bins=bins, time_resolution=time_res, spectra_compression=spectra_compress)\n",
    "    elec1 = f(df, 1)\n",
    "    elec6 = f(df,6)\n",
    "    return acc + np.concatenate([elec1,elec6]).tolist()\n",
    "    #return acc + elec1.tolist()\n",
    "\n",
    "def vectors (dataframes):\n",
    "    return list(reduce(featureify, dataframes, []))\n",
    "\n",
    "def load_feature_vectors(id=None, task=None):\n",
    "    return vectors(map(load_recording,\n",
    "                   find_recordings(id, task)))\n",
    "\n",
    "breathe_features = load_feature_vectors(id='001', task='breathe')\n",
    "\n",
    "(len(breathe_features), len(breathe_features[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 0.061695092337472973)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's a realy simple test of authentication power\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler  = preprocessing.RobustScaler()\n",
    "max_breathe = load_feature_vectors(id='001', task='breathe')\n",
    "john_breathe = load_feature_vectors(id='002', task='breathe')\n",
    "X = scaler.fit_transform(X)\n",
    "X, y = vectors_labels(max_breathe, john_breathe)\n",
    "cv = cross_val_svm(X,y,7)\n",
    "(cv.mean(),cv.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   test-auc-mean  test-auc-std  test-map-mean  test-map-std  train-auc-mean  \\\n0            1.0           0.0            1.0           0.0             1.0   \n\n   train-auc-std  train-map-mean  train-map-std  \n0            0.0             1.0            0.0  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhUAAAFyCAYAAABC/SgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJKkIgwVkiSpiP8FsgegJwgedN8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c7c424518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here's a fancier version of above using xgboost\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "#from sklearn.grid_search impo\n",
    "\n",
    "# eval_metrics:\n",
    "# http://xgboost.readthedocs.io/en/latest//parameter.html\n",
    "metrics = ['auc', 'map']\n",
    "\n",
    "def cv (alg,X,y,nfold=7):\n",
    "    xgtrain = xgb.DMatrix(X,y)\n",
    "    param = alg.get_xgb_params()\n",
    "    cvresults = xgb.cv(param,\n",
    "                      xgtrain,\n",
    "                      num_boost_round=alg.get_params()['n_estimators'],\n",
    "                      nfold=nfold,\n",
    "                      metrics=metrics,\n",
    "                      early_stopping_rounds=50)\n",
    "    alg.set_params(n_estimators=cvresults.shape[0])\n",
    "    alg.fit(X,y,eval_metric=metrics)\n",
    "    return alg, cvresults\n",
    "\n",
    "def inspect (alg):\n",
    "    #Predict training set:\n",
    "    #dtrain_predictions = alg.predict(X)\n",
    "    #dtrain_predprob = alg.predict_proba(X)[:,1]\n",
    "    ##Print model report:\n",
    "    #print(\"Accuracy : %.4g\" % metrics.accuracy_score(y, dtrain_predictions))\n",
    "    #print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, dtrain_predprob))\n",
    "    features = alg.booster().get_fscore()\n",
    "    feat_imp = pd.Series(features).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "\n",
    "\n",
    "def fresh_xgb ():\n",
    "    return XGBClassifier(\n",
    "         learning_rate =0.1,\n",
    "         n_estimators=1000,\n",
    "         max_depth=5,\n",
    "         min_child_weight=1,\n",
    "         gamma=0,\n",
    "         subsample=0.8,\n",
    "         colsample_bytree=0.8,\n",
    "         objective= 'binary:logistic',\n",
    "         nthread=4,\n",
    "         scale_pos_weight=1,\n",
    "         seed=27) \n",
    "\n",
    "X, y = vectors_labels(\n",
    "    max_breathe,\n",
    "    john_breathe)\n",
    "\n",
    "alg, cvresults = cv(fresh_xgb(), X,y)\n",
    "inspect(alg)\n",
    "# see result of last cv round\n",
    "cvresults[-1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAR': 0.0, 'FRR': 0.0}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns FAR, FRR\n",
    "def far_frr (alg, X, y):\n",
    "    false_accept = 0\n",
    "    false_reject = 0\n",
    "    predicted_labels = alg.predict(X)\n",
    "    for idx, predicted_label in enumerate(predicted_labels):\n",
    "        correct_label = y[idx]\n",
    "        if (predicted_label==correct_label):\n",
    "           continue\n",
    "        elif (predicted_label==0):\n",
    "           false_accept+=1\n",
    "           continue\n",
    "        false_reject+=1\n",
    "    def rate (num):\n",
    "        return num/len(X)\n",
    "    return { 'FAR': rate(false_accept),\n",
    "             'FRR': rate(false_reject) }\n",
    "\n",
    "alg, cvresults = cv(fresh_xgb(), X,y)\n",
    "far_frr(alg, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def withold_final (n, lst):\n",
    "    return lst[:-1*n]\n",
    "withold_final (2, [1,2,3,4,5]) == [1, 2, 3]\n",
    "def get_final (n, lst):\n",
    "    return lst[-1*n:]\n",
    "get_final(1, [1,2,3,4,5]) == [5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FAR': 0.0, 'FRR': 0.0}"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_auth (task, num_to_withold=0):\n",
    "\n",
    "    def trainset (vectors):\n",
    "        if (num_to_withold):\n",
    "            return withold_final(num_to_withold, vectors)\n",
    "        return vectors\n",
    "\n",
    "    def testset (vectors):\n",
    "        if (num_to_withold):\n",
    "            return get_final(num_to_withold, vectors)\n",
    "        return vectors\n",
    "\n",
    "    # get `task` by this `subject`\n",
    "    this_persons_features =  load_feature_vectors('001', task=task)      # HACK just using subj 1 for now\n",
    "    # get `task` NOT from this `subject`\n",
    "    not_this_persons_features =  load_feature_vectors('002', task=task)  \n",
    "    # turn these pos/neg features into vectors, labels X, y\n",
    "    trainX, trainy = vectors_labels(trainset(this_persons_features),\n",
    "                                    trainset(not_this_persons_features))\n",
    "    # fit an alg over 7 cv rounds\n",
    "    alg, cvresults = cv(fresh_xgb(),\n",
    "                        trainX, trainy,\n",
    "                        nfold=7)\n",
    "\n",
    "    # turn these pos/neg features into vectors, labels X, y\n",
    "    testX, testy= vectors_labels(testset(this_persons_features),\n",
    "                                 testset(not_this_persons_features))\n",
    "    # get far, frr\n",
    "    return far_frr(alg, testX, testy)\n",
    "\n",
    "test_auth(task_names[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          task      FAR  FRR\n",
       "0        sport  0.00000  0.0\n",
       "1  listennoise  0.00000  0.0\n",
       "2    breathe_o  0.00000  0.0\n",
       "3         song  0.00000  0.0\n",
       "4      breathe  0.00000  0.0\n",
       "5       speech  0.00000  0.0\n",
       "6     sequence  0.00000  0.0\n",
       "7   listentone  0.01875  0.0\n",
       "8       song_o  0.00000  0.0\n",
       "9         face  0.00625  0.0"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "when I do \n",
    "\n",
    "    for task in task_names:\n",
    "        print(task, test_auth(task))\n",
    "\n",
    "the results are perfect...........too perfect\n",
    "I think we are overfitting.\n",
    "\n",
    "its confusing, but in the cv round, we are doing 7 rounds of cv to generate some parameters\n",
    "then, we fit those parameters to the algorithm, and return it\n",
    "so, when we test on that same data later, we are effectively testing on the train set,\n",
    "since the paramaters were generated from there.\n",
    "\n",
    "\n",
    "as a simple (dumb) solution, lets withold the last n samples of each group (positive, negative) for testing\n",
    "'''\n",
    "stats = ['FAR','FRR']\n",
    "df = pd.DataFrame(columns=['task'] + stats)\n",
    "for idx, task in enumerate(task_names):\n",
    "    results = test_auth(task, num_to_withold=80) #80 = 80% of the 100 samples per subject\n",
    "    results_stats = [results[stat] for stat in stats]\n",
    "    row = [task]+results_stats\n",
    "    df.loc[idx] = row\n",
    "    #df.append(row)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('n-of-2-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "autoscroll": "json-false",
    "collapsed": false,
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# summary\n",
    "\n",
    "i used xgboost to generate a binary classifier.\n",
    "\n",
    "attached is the FAR and FRR for Maxs passthoughts against John. (since we only have 2 subjects, theres no need to calculate Johns - it should be the same).\n",
    "\n",
    "i witheld 80% of the recordings for the test set (and trained on remaining 20%).\n",
    "we did amazingly well I think.\n",
    "\n",
    "of course, our sample-size is 2.\n",
    "clearly we will need to get more data to get a reasonable estimate.\n",
    "\n",
    "once we do, here is what we should try next, aside from what weve already done:\n",
    "\n",
    "1. Incorporate readings from other people ASIDE from the target task. Sure, your \"sport\" gesture couldnt spoof my \"sport\" gesture, but could your \"breathe\" gesture?\n",
    "\n",
    "2. Figure out a way to SAVE and LOAD trained algorithms, so we can do online authentication in the future.\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "Untitled.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
